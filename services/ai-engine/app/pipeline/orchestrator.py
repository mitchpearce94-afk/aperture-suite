"""
Pipeline Orchestrator

Runs the full AI processing pipeline for a gallery:
    Phase 0: Analysis (EXIF, scene, quality, faces, duplicates)
    Phase 1: Style application (preset baseline + learned profile)
    Phase 4: Composition (horizon fix, crop optimisation)
    Phase 5: QA & Output (web-res, thumbnails, top-N selection)

Phases 2 (retouching) and 3 (cleanup) are architecture-ready stubs
that will plug into GPU-accelerated models later.

Updates Supabase in real-time: processing_job status, photo records,
gallery photo_count.
"""
import io
import logging
import traceback
from datetime import datetime, timezone

import numpy as np
import cv2
from PIL import Image

from app.pipeline.phase0_analysis import analyse_image, group_duplicates
from app.pipeline.phase1_style import apply_style, load_image_from_bytes
from app.pipeline.phase4_composition import fix_composition
from app.pipeline.phase5_output import generate_outputs, select_top_images, get_output_keys
from app.storage.supabase_storage import download_photo, upload_photo
from app.storage.db import (
    get_gallery_photos, update_photo, bulk_update_photos,
    set_job_phase, complete_job, fail_job,
    get_gallery, update_gallery, update_job_status,
    get_style_profile, get_photographer_default_style,
    validate_style_profile_ownership,
)

log = logging.getLogger(__name__)

# Max dimension for processing — keeps memory under ~200MB per image
# Full-res output is generated by applying the same edits to the original
PROCESSING_MAX_DIM = 2048


def resize_for_processing(img: np.ndarray, max_dim: int = PROCESSING_MAX_DIM) -> np.ndarray:
    """Resize image to fit within max_dim while preserving aspect ratio."""
    h, w = img.shape[:2]
    if max(h, w) <= max_dim:
        return img
    scale = max_dim / max(h, w)
    new_w, new_h = int(w * scale), int(h * scale)
    return cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)


def decode_image(image_bytes: bytes) -> np.ndarray | None:
    """Decode image bytes to BGR numpy array, handling RAW formats."""
    nparr = np.frombuffer(image_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    if img is not None:
        return img

    try:
        import rawpy
        raw = rawpy.imread(io.BytesIO(image_bytes))
        rgb = raw.postprocess(
            use_camera_wb=True,
            half_size=False,
            no_auto_bright=True,
            output_bps=8,
        )
        return cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
    except Exception:
        pass

    try:
        pil_img = Image.open(io.BytesIO(image_bytes))
        pil_img = pil_img.convert("RGB")
        return np.array(pil_img)[:, :, ::-1]
    except Exception:
        return None


def run_pipeline(
    processing_job_id: str,
    gallery_id: str,
    style_profile_id: str | None = None,
    settings_override: dict | None = None,
    included_images: int | None = None,
):
    """
    Main pipeline entry point. Processes all photos in a gallery.

    Style profile isolation (FIX #1):
    - If style_profile_id is provided, validates it belongs to the gallery's photographer
    - If not provided, auto-selects the photographer's default ready style profile
    - Never cross-contaminates between photographers
    """
    log.info(f"Starting pipeline for gallery {gallery_id} (job {processing_job_id})")

    settings = settings_override or {}
    style_profile = None

    try:
        # Fetch gallery to get photographer_id
        gallery = get_gallery(gallery_id)
        if not gallery:
            fail_job(processing_job_id, f"Gallery {gallery_id} not found")
            return

        photographer_id = gallery["photographer_id"]
        log.info(f"Photographer: {photographer_id}")

        # ── STYLE PROFILE ISOLATION ──────────────────────
        if style_profile_id:
            # Validate the style profile belongs to THIS photographer
            if not validate_style_profile_ownership(style_profile_id, photographer_id):
                log.warning(
                    f"Style profile {style_profile_id} does not belong to "
                    f"photographer {photographer_id} — ignoring"
                )
                style_profile_id = None
            else:
                profile_record = get_style_profile(style_profile_id)
                if profile_record and profile_record.get("status") == "ready":
                    style_profile = profile_record.get("settings", {})
                    log.info(f"Using style profile: {profile_record.get('name')}")
                else:
                    log.warning(f"Style profile {style_profile_id} not ready")

        # Auto-select photographer's default style if none specified/valid
        if not style_profile:
            default = get_photographer_default_style(photographer_id)
            if default:
                style_profile = default.get("settings", {})
                log.info(f"Auto-selected photographer's default style: {default.get('name')}")
            else:
                log.info("No style profile available — processing without style")

        # Fetch all photos — skip already-processed ones (have edited_key)
        all_photos = get_gallery_photos(gallery_id)
        photos = [p for p in all_photos if not p.get("edited_key")]
        if not photos:
            # All photos already processed — nothing new to do
            if all_photos:
                log.info("All photos already processed — nothing new to process")
                complete_job(processing_job_id, 0)
                return
            fail_job(processing_job_id, "No photos found in gallery")
            return

        total = len(photos)
        log.info(f"Processing {total} photos")

        set_job_phase(processing_job_id, "analysis", 0)

        # ─────────────────────────────────────────────────
        # PHASE 0: Analysis
        # ─────────────────────────────────────────────────
        log.info("Phase 0: Analysis")
        analysis_results = []

        for i, photo in enumerate(photos):
            try:
                image_bytes = download_photo(photo["original_key"])
                if not image_bytes:
                    log.warning(f"Could not download photo {photo['id']}")
                    update_photo(photo["id"], status="rejected", needs_review=True)
                    continue

                result = analyse_image(image_bytes)

                if "error" in result:
                    update_photo(photo["id"], status="rejected", needs_review=True)
                    continue

                update_photo(
                    photo["id"],
                    exif_data=result["exif_data"],
                    scene_type=result["scene_type"],
                    quality_score=int(result["quality_score"]),
                    face_data=result["face_data"],
                    width=int(result["width"]),
                    height=int(result["height"]),
                    status="processing",
                )

                analysis_results.append({
                    "id": photo["id"],
                    "original_key": photo["original_key"],
                    "filename": photo.get("filename", "unknown"),
                    "quality_score": result["quality_score"],
                    "scene_type": result["scene_type"],
                    "face_data": result["face_data"],
                    "phash": result["phash"],
                })
                # Don't store image_bytes — re-download in Phase 1 to save memory

            except Exception as e:
                log.error(f"Phase 0 failed for photo {photo['id']}: {e}")
                update_photo(photo["id"], status="rejected", needs_review=True)

            set_job_phase(processing_job_id, "analysis", i + 1)

        if not analysis_results:
            fail_job(processing_job_id, "All photos failed analysis")
            return

        # Duplicate grouping
        duplicate_groups = group_duplicates(
            [{"id": r["id"], "_phash": r["phash"]} for r in analysis_results]
        )

        # ─────────────────────────────────────────────────
        # IMAGE SELECTION
        # ─────────────────────────────────────────────────
        if included_images and included_images > 0 and included_images < len(analysis_results):
            log.info(f"Selecting top {included_images} of {len(analysis_results)} images")
            selected_ids = select_top_images(
                [{"id": r["id"], "quality_score": r["quality_score"], "scene_type": r["scene_type"]}
                 for r in analysis_results],
                included_images,
                duplicate_groups,
            )
            all_ids = {r["id"] for r in analysis_results}
            culled_ids = list(all_ids - set(selected_ids))
            if culled_ids:
                bulk_update_photos(culled_ids, is_culled=True, status="rejected")
            analysis_results = [r for r in analysis_results if r["id"] in selected_ids]

        # ─────────────────────────────────────────────────
        # PHASE 1: Style Application
        # ─────────────────────────────────────────────────
        log.info("Phase 1: Style Application")
        set_job_phase(processing_job_id, "style", len(photos) - len(analysis_results))

        for i, result in enumerate(analysis_results):
            try:
                # Re-download image for processing (not stored from Phase 0 to save memory)
                raw = download_photo(result["original_key"])
                if not raw:
                    continue
                img = decode_image(raw)
                del raw  # Free raw bytes immediately
                if img is None:
                    continue

                # Resize for processing — saves memory on Railway (512MB)
                img = resize_for_processing(img)

                if style_profile:
                    intensity = settings.get("style_intensity", 0.75)
                    img = apply_style(img, style_profile, intensity=intensity)

                result["processed_img"] = img

            except Exception as e:
                log.error(f"Phase 1 failed for {result['id']}: {e}")

            set_job_phase(
                processing_job_id, "style",
                len(photos) - len(analysis_results) + i + 1,
            )

        # ─────────────────────────────────────────────────
        # PHASE 2: Face & Skin Retouching (STUB)
        # ─────────────────────────────────────────────────
        log.info("Phase 2: Retouching (basic — GPU models not loaded)")
        set_job_phase(processing_job_id, "retouch", 0)

        for i, result in enumerate(analysis_results):
            img = result.get("processed_img")
            if img is not None and settings.get("retouch_intensity", "light") != "off":
                blurred = cv2.GaussianBlur(img, (0, 0), 3)
                img = cv2.addWeighted(img, 1.3, blurred, -0.3, 0)
                result["processed_img"] = img
            set_job_phase(processing_job_id, "retouch", i + 1)

        # ─────────────────────────────────────────────────
        # PHASE 3: Scene Cleanup (STUB)
        # ─────────────────────────────────────────────────
        log.info("Phase 3: Cleanup (skipped — requires GPU models)")
        set_job_phase(processing_job_id, "cleanup", len(analysis_results))

        # ─────────────────────────────────────────────────
        # PHASE 4: Composition
        # ─────────────────────────────────────────────────
        log.info("Phase 4: Composition")
        set_job_phase(processing_job_id, "composition", 0)

        auto_crop = settings.get("auto_crop", True)

        for i, result in enumerate(analysis_results):
            try:
                img = result.get("processed_img")
                if img is None:
                    continue

                img, comp_meta = fix_composition(
                    img,
                    face_boxes=result.get("face_data", []),
                    auto_crop=auto_crop,
                )
                result["processed_img"] = img
                result["composition"] = comp_meta

            except Exception as e:
                log.error(f"Phase 4 failed for {result['id']}: {e}")

            set_job_phase(processing_job_id, "composition", i + 1)

        # ─────────────────────────────────────────────────
        # PHASE 5: QA & Output
        # ─────────────────────────────────────────────────
        log.info("Phase 5: QA & Output")
        set_job_phase(processing_job_id, "output", 0)

        processed_count = 0

        for i, result in enumerate(analysis_results):
            try:
                img = result.get("processed_img")
                if img is None:
                    continue

                outputs = generate_outputs(img)
                keys = get_output_keys(photographer_id, gallery_id, result["filename"])

                edited_ok = upload_photo(keys["edited_key"], outputs["full_res"])
                web_ok = upload_photo(keys["web_key"], outputs["web_res"])
                thumb_ok = upload_photo(keys["thumb_key"], outputs["thumbnail"])

                if edited_ok and web_ok and thumb_ok:
                    update_photo(
                        result["id"],
                        edited_key=keys["edited_key"],
                        web_key=keys["web_key"],
                        thumb_key=keys["thumb_key"],
                        width=outputs["full_width"],
                        height=outputs["full_height"],
                        status="edited",
                        edit_confidence=int(result.get("quality_score", 75)),
                        ai_edits={
                            "style_applied": style_profile is not None,
                            "style_version": style_profile.get("version", "1.0") if style_profile else None,
                            "has_preset": style_profile.get("has_preset", False) if style_profile else False,
                            "composition": result.get("composition", {}),
                            "pipeline_version": "2.0",
                        },
                    )
                    processed_count += 1
                else:
                    update_photo(result["id"], status="rejected", needs_review=True)

            except Exception as e:
                log.error(f"Phase 5 failed for {result['id']}: {e}")
                update_photo(result["id"], status="rejected", needs_review=True)

            set_job_phase(processing_job_id, "output", i + 1)

            result.pop("processed_img", None)
            result.pop("image_bytes", None)

        # ─────────────────────────────────────────────────
        # COMPLETE
        # ─────────────────────────────────────────────────
        log.info(f"Pipeline complete: {processed_count}/{total} photos processed")

        complete_job(processing_job_id, processed_count)
        update_gallery(gallery_id, status="ready")

        if gallery and gallery.get("job"):
            job = gallery["job"]
            if isinstance(job, dict):
                update_job_status(job["id"], "ready_for_review")

    except Exception as e:
        log.error(f"Pipeline failed: {e}\n{traceback.format_exc()}")
        fail_job(processing_job_id, str(e))
